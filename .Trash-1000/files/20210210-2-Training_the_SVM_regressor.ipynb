{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "academic-equivalent",
   "metadata": {},
   "source": [
    "# 1. Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "purple-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import scipy as sci\n",
    "from typing import Tuple, Dict, Any\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing._data import StandardScaler\n",
    "\n",
    "def train_svr_regressor(\n",
    "        X_train: pd.DataFrame,\n",
    "        tp_x_train: pd.DataFrame,\n",
    "        tp_y_train: pd.DataFrame,\n",
    "        kernel: str,\n",
    "        gamma: str,\n",
    "    ) -> Tuple[svm._classes.SVR,Dict]:\n",
    "\n",
    "    # Initializing hyperparameters for tp_x\n",
    "    tp_x_response_scale = sci.stats.iqr(tp_x_train)\n",
    "    tp_x_box_constraint = tp_x_response_scale/1.349\n",
    "    tp_x_epsilon = 2*tp_x_response_scale/13.49\n",
    "    \n",
    "    # Initializing hyperparameters for tp_y\n",
    "    tp_y_response_scale = sci.stats.iqr(tp_y_train)\n",
    "    tp_y_box_constraint = tp_y_response_scale/1.349\n",
    "    tp_y_epsilon = 2*tp_y_response_scale/13.49\n",
    "\n",
    "    # Initializing the model for tp_x\n",
    "    tp_x_model = svm.SVR(\n",
    "        kernel = kernel,\n",
    "        C = tp_x_box_constraint,\n",
    "        gamma = gamma,\n",
    "        epsilon = tp_x_epsilon\n",
    "    )\n",
    "\n",
    "    # Initializing the model for tp_y\n",
    "    tp_y_model = svm.SVR(\n",
    "        kernel = kernel,\n",
    "        C = tp_y_box_constraint,\n",
    "        gamma = gamma,\n",
    "        epsilon = tp_y_epsilon\n",
    "    )\n",
    "\n",
    "    # Training the tp_x model\n",
    "    time_start = time.time()\n",
    "    tp_x_model.fit(X_train.drop('partition_key', axis=1), tp_x_train)\n",
    "    time_end = time.time()\n",
    "\n",
    "    # Elapsed time in seconds for tp_x\n",
    "    tp_x_elapsed_time = time_end - time_start\n",
    "\n",
    "    # Training the tp_y model\n",
    "    time_start = time.time()\n",
    "    tp_y_model.fit(X_train.drop('partition_key', axis=1), tp_y_train)\n",
    "    time_end = time.time()\n",
    "\n",
    "    # Elapsed time in seconds for tp_x\n",
    "    tp_y_elapsed_time = time_end - time_start\n",
    "\n",
    "    metrics = {\n",
    "        \"tp_x_training_elapsed_time\": {\n",
    "            \"value\": float(tp_x_elapsed_time),\n",
    "             \"step\": 1\n",
    "         },\n",
    "        \"tp_y_training_elapsed_time\": {\n",
    "            \"value\": float(tp_y_elapsed_time),\n",
    "            \"step\": 1\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return tp_x_model, tp_y_model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "patent-neighbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-10 20:28:00,580 - kedro.io.data_catalog - INFO - Loading data from `regressor_x_train` (CSVDataSet)...\n",
      "2021-02-10 20:28:00,589 - kedro.io.data_catalog - INFO - Loading data from `regressor_tp_x_train` (CSVDataSet)...\n",
      "2021-02-10 20:28:00,595 - kedro.io.data_catalog - INFO - Loading data from `regressor_tp_y_train` (CSVDataSet)...\n",
      "2021-02-10 20:28:00,602 - kedro.io.data_catalog - INFO - Loading data from `params:regressor.svr.hyperp.kernel` (MemoryDataSet)...\n",
      "2021-02-10 20:28:00,604 - kedro.io.data_catalog - INFO - Loading data from `params:regressor.svr.hyperp.gamma` (MemoryDataSet)...\n"
     ]
    }
   ],
   "source": [
    "X_train = catalog.load(\"regressor_x_train\")\n",
    "tp_x_train = catalog.load(\"regressor_tp_x_train\")\n",
    "tp_y_train = catalog.load(\"regressor_tp_y_train\")\n",
    "svr_kernel = catalog.load(\"params:regressor.svr.hyperp.kernel\")\n",
    "svr_gamma = catalog.load(\"params:regressor.svr.hyperp.gamma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "permanent-deputy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user01/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/home/user01/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/home/user01/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "tp_x_trained_model, tp_y_trained_model, metrics = train_svr_regressor(\n",
    "    X_train = X_train,\n",
    "    tp_x_train = tp_x_train,\n",
    "    tp_y_train = tp_y_train,\n",
    "    kernel = svr_kernel,\n",
    "    gamma = svr_gamma,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-prize",
   "metadata": {},
   "source": [
    "# 2. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "delayed-logging",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user01/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_svr_regressor(\n",
    "        tp_x_model: svm._classes.SVR,\n",
    "        tp_y_model: svm._classes.SVR,\n",
    "        X_scaler: StandardScaler,\n",
    "        tp_x_scaler: StandardScaler,\n",
    "        tp_y_scaler: StandardScaler,\n",
    "        X_test: pd.DataFrame,\n",
    "        tp_x_test: pd.DataFrame,\n",
    "        tp_y_test: pd.DataFrame,\n",
    "    ) -> Dict[str, Dict[str, Any]]:\n",
    "\n",
    "    # Removing partition key from the data frame\n",
    "    X_test.drop('partition_key', axis=1, inplace=True)\n",
    "\n",
    "    # Generate predictions for tp_x\n",
    "    tp_x_pred = tp_x_model.predict(X_test)\n",
    "    tp_x_scaled_rmse = mean_squared_error(\n",
    "        y_true = tp_x_test.values.reshape(tp_x_test.values.shape[0],),\n",
    "        y_pred = tp_x_pred\n",
    "    )\n",
    "    \n",
    "    # Generate predictions for tp_y\n",
    "    tp_y_pred = tp_y_model.predict(X_test)\n",
    "    tp_y_scaled_rmse = mean_squared_error(\n",
    "        y_true = tp_y_test.values.reshape(tp_y_test.values.shape[0],),\n",
    "        y_pred = tp_y_pred\n",
    "    )\n",
    "\n",
    "    # Inverse transform the data with the scaler\n",
    "    inversed_X_test_data = X_scaler.inverse_transform(X_test)\n",
    "    inversed_tp_x_test = tp_x_scaler.inverse_transform(tp_x_test)\n",
    "    inversed_tp_y_test = tp_y_scaler.inverse_transform(tp_y_test)\n",
    "    inversed_tp_x_pred = tp_x_scaler.inverse_transform(tp_x_pred)\n",
    "    inversed_tp_y_pred = tp_y_scaler.inverse_transform(tp_y_pred)\n",
    "\n",
    "    tp_x_unscaled_rmse = mean_squared_error(\n",
    "        y_true = inversed_tp_x_test,\n",
    "        y_pred = inversed_tp_x_pred\n",
    "    )\n",
    "    \n",
    "    tp_y_unscaled_rmse = mean_squared_error(\n",
    "        y_true = inversed_tp_y_test,\n",
    "        y_pred = inversed_tp_y_pred\n",
    "    )\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"tp_x_scaled_rmse\": {\"value\": float(tp_x_scaled_rmse), \"step\": 1},\n",
    "        \"tp_x_unscaled_rmse\": {\"value\": float(tp_x_unscaled_rmse), \"step\": 1},\n",
    "        \"tp_y_scaled_rmse\": {\"value\": float(tp_y_scaled_rmse), \"step\": 1},\n",
    "        \"tp_y_unscaled_rmse\": {\"value\": float(tp_y_unscaled_rmse), \"step\": 1},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "studied-replica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-10 20:40:31,180 - kedro.io.data_catalog - INFO - Loading data from `regressor_x_scaler` (MlflowMlflowModelSaverDataSet)...\n",
      "2021-02-10 20:40:31,187 - kedro.io.data_catalog - INFO - Loading data from `regressor_tp_x_scaler` (MlflowMlflowModelSaverDataSet)...\n",
      "2021-02-10 20:40:31,196 - kedro.io.data_catalog - INFO - Loading data from `regressor_tp_y_scaler` (MlflowMlflowModelSaverDataSet)...\n",
      "2021-02-10 20:40:31,209 - kedro.io.data_catalog - INFO - Loading data from `regressor_x_test` (CSVDataSet)...\n",
      "2021-02-10 20:40:31,224 - kedro.io.data_catalog - INFO - Loading data from `regressor_tp_x_test` (CSVDataSet)...\n",
      "2021-02-10 20:40:31,234 - kedro.io.data_catalog - INFO - Loading data from `regressor_tp_y_test` (CSVDataSet)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tp_x_scaled_rmse': {'value': 0.9225904691474833, 'step': 1},\n",
       " 'tp_x_unscaled_rmse': {'value': 31.956953281033293, 'step': 1},\n",
       " 'tp_y_scaled_rmse': {'value': 1.1870944350459145, 'step': 1},\n",
       " 'tp_y_unscaled_rmse': {'value': 30.430529492396364, 'step': 1}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = evaluate_svr_regressor(\n",
    "    tp_x_model = tp_x_trained_model, \n",
    "    tp_y_model = tp_y_trained_model,\n",
    "    X_scaler = catalog.load(\"regressor_x_scaler\"),\n",
    "    tp_x_scaler = catalog.load(\"regressor_tp_x_scaler\"),\n",
    "    tp_y_scaler = catalog.load(\"regressor_tp_y_scaler\"),\n",
    "    X_test = catalog.load(\"regressor_x_test\"),\n",
    "    tp_x_test = catalog.load(\"regressor_tp_x_test\"),\n",
    "    tp_y_test = catalog.load(\"regressor_tp_y_test\"),\n",
    ")\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KedroMLFlowTutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
