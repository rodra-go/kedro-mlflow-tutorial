{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "downtown-reservation",
   "metadata": {},
   "source": [
    "# 1. Loading partitioned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "broadband-marketing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-23 23:48:24,672 - kedro.io.data_catalog - INFO - Loading data from `sgs_dataset` (PartitionedDataSet)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user01/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "sgs_dataset = catalog.load('sgs_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "underlying-excellence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>xx</th>\n",
       "      <th>yy</th>\n",
       "      <th>zz</th>\n",
       "      <th>speed_x</th>\n",
       "      <th>speed_y</th>\n",
       "      <th>speed_z</th>\n",
       "      <th>speed_xx</th>\n",
       "      <th>...</th>\n",
       "      <th>rupture_time</th>\n",
       "      <th>session_id</th>\n",
       "      <th>swell_dir</th>\n",
       "      <th>swell_hs</th>\n",
       "      <th>swell_tp</th>\n",
       "      <th>wave_dir</th>\n",
       "      <th>wave_hs</th>\n",
       "      <th>wave_tp</th>\n",
       "      <th>win_dir</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.300000</td>\n",
       "      <td>15.700000</td>\n",
       "      <td>-16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>244.50000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.86</td>\n",
       "      <td>201.2</td>\n",
       "      <td>2.71</td>\n",
       "      <td>13.3</td>\n",
       "      <td>85.7</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.316316</td>\n",
       "      <td>15.708154</td>\n",
       "      <td>-16.020592</td>\n",
       "      <td>-0.061946</td>\n",
       "      <td>0.011578</td>\n",
       "      <td>244.50244</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>-0.001770</td>\n",
       "      <td>-0.039725</td>\n",
       "      <td>-0.120705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.86</td>\n",
       "      <td>201.2</td>\n",
       "      <td>2.71</td>\n",
       "      <td>13.3</td>\n",
       "      <td>85.7</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.359290</td>\n",
       "      <td>15.730342</td>\n",
       "      <td>-16.075703</td>\n",
       "      <td>-0.231323</td>\n",
       "      <td>0.035530</td>\n",
       "      <td>244.50719</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>-0.067912</td>\n",
       "      <td>-0.212014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.86</td>\n",
       "      <td>201.2</td>\n",
       "      <td>2.71</td>\n",
       "      <td>13.3</td>\n",
       "      <td>85.7</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416484</td>\n",
       "      <td>15.761158</td>\n",
       "      <td>-16.149070</td>\n",
       "      <td>-0.471763</td>\n",
       "      <td>0.053906</td>\n",
       "      <td>244.50937</td>\n",
       "      <td>-0.000480</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>-0.075733</td>\n",
       "      <td>-0.261404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.86</td>\n",
       "      <td>201.2</td>\n",
       "      <td>2.71</td>\n",
       "      <td>13.3</td>\n",
       "      <td>85.7</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.478907</td>\n",
       "      <td>15.794098</td>\n",
       "      <td>-16.218199</td>\n",
       "      <td>-0.738104</td>\n",
       "      <td>0.057024</td>\n",
       "      <td>244.50912</td>\n",
       "      <td>-0.002962</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>-0.060947</td>\n",
       "      <td>-0.263505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>3.86</td>\n",
       "      <td>201.2</td>\n",
       "      <td>2.71</td>\n",
       "      <td>13.3</td>\n",
       "      <td>85.7</td>\n",
       "      <td>5.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          x          y          z        xx        yy         zz   speed_x  \\\n",
       "0 -0.300000  15.700000 -16.000000  0.000000  0.000000  244.50000  0.000000   \n",
       "1 -0.316316  15.708154 -16.020592 -0.061946  0.011578  244.50244  0.005226   \n",
       "2 -0.359290  15.730342 -16.075703 -0.231323  0.035530  244.50719  0.004281   \n",
       "3 -0.416484  15.761158 -16.149070 -0.471763  0.053906  244.50937 -0.000480   \n",
       "4 -0.478907  15.794098 -16.218199 -0.738104  0.057024  244.50912 -0.002962   \n",
       "\n",
       "    speed_y   speed_z  speed_xx  ...  rupture_time  session_id  swell_dir  \\\n",
       "0  0.000000  0.000000  0.000000  ...           0.0          22       93.0   \n",
       "1 -0.001770 -0.039725 -0.120705  ...           0.0          22       93.0   \n",
       "2  0.000331 -0.067912 -0.212014  ...           0.0          22       93.0   \n",
       "3  0.003851 -0.075733 -0.261404  ...           0.0          22       93.0   \n",
       "4  0.003428 -0.060947 -0.263505  ...           0.0          22       93.0   \n",
       "\n",
       "   swell_hs  swell_tp  wave_dir  wave_hs  wave_tp  win_dir  wind_speed  \n",
       "0      0.64      3.86     201.2     2.71     13.3     85.7        5.37  \n",
       "1      0.64      3.86     201.2     2.71     13.3     85.7        5.37  \n",
       "2      0.64      3.86     201.2     2.71     13.3     85.7        5.37  \n",
       "3      0.64      3.86     201.2     2.71     13.3     85.7        5.37  \n",
       "4      0.64      3.86     201.2     2.71     13.3     85.7        5.37  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgs_dataset['22_0531_pos.csv']().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-patrick",
   "metadata": {},
   "source": [
    "# 2.Transforming Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "permanent-bulgaria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user01/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import math as mt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, Dict, Callable, Any, List, Union\n",
    "\n",
    "\n",
    "def transform_positions(\n",
    "        partitioned_input: Dict[str, Callable[[], Any]],\n",
    "    ) -> Dict[str, pd.DataFrame]:\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    for partition_key, partition_load_func in tqdm(\n",
    "            sorted(partitioned_input.items())\n",
    "        ):\n",
    "        partition_data = partition_load_func()  # load the actual partition data\n",
    "        result[partition_key] = apply_rotation_matrix(\n",
    "            partition_data['x'].values,\n",
    "            partition_data['y'].values,\n",
    "            partition_data['z'].values,\n",
    "            partition_data['xx'].values,\n",
    "            partition_data['yy'].values,\n",
    "            partition_data['zz'].values,\n",
    "        )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def apply_rotation_matrix(\n",
    "        X: np.ndarray,\n",
    "        Y: np.ndarray,\n",
    "        Z: np.ndarray,\n",
    "        XX: np.ndarray,\n",
    "        YY: np.ndarray,\n",
    "        ZZ: np.ndarray,\n",
    "        ignore_size: int = 500\n",
    "    ) -> np.ndarray:\n",
    "    '''\n",
    "    Applies the rotation matrix to transform absolute coordinates to\n",
    "    local coordinates.\n",
    "\n",
    "        Parameters:\n",
    "            X (np.ndarray): X in absolute coordinates\n",
    "            Y (np.ndarray): Y in absolute coordinates\n",
    "            Z (np.ndarray): Z in absolute coordinates\n",
    "            XX (np.ndarray): XX in absolute coordinates\n",
    "            YY (np.ndarray): YY in absolute coordinates\n",
    "            ZZ (np.ndarray): ZZ in absolute coordinates\n",
    "            ignore_size (:obj:`int`, optional): Steps to ignore in the\n",
    "                beggining of the series to remove transitive effects.\n",
    "                Default value is 500 points\n",
    "\n",
    "        Returns:\n",
    "            rotated (np.ndarray): local coordinates\n",
    "    '''\n",
    "    # Transform roll, pitch, and yaw to radians\n",
    "    roll = (XX*mt.pi)/180\n",
    "    pitch = (YY*mt.pi)/180\n",
    "    yaw = (ZZ*mt.pi)/180\n",
    "\n",
    "    # Apply rotation matrix to X and Y\n",
    "    x = X * np.cos(yaw) + Y * np.sin(yaw)\n",
    "    y = -X * np.sin(yaw) + Y * np.cos(yaw)\n",
    "\n",
    "    #Ignore the first points due to transitions effects\n",
    "    return pd.DataFrame({\n",
    "        'x': x[ignore_size:],\n",
    "        'y': y[ignore_size:],\n",
    "        'z': Z[ignore_size:],\n",
    "        'roll': roll[ignore_size:],\n",
    "        'pitch': pitch[ignore_size:],\n",
    "        'yaw': yaw[ignore_size:],\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cubic-technician",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:08<00:00, 11.47it/s]\n"
     ]
    }
   ],
   "source": [
    "transformed_sgs_dataset = transform_positions(\n",
    "    partitioned_input = sgs_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interracial-asian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>roll</th>\n",
       "      <th>pitch</th>\n",
       "      <th>yaw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-13.766946</td>\n",
       "      <td>-8.285960</td>\n",
       "      <td>-16.280176</td>\n",
       "      <td>-0.013512</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>4.271540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.746646</td>\n",
       "      <td>-8.279071</td>\n",
       "      <td>-16.282722</td>\n",
       "      <td>-0.015320</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>4.271894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-13.726923</td>\n",
       "      <td>-8.256329</td>\n",
       "      <td>-16.266628</td>\n",
       "      <td>-0.016726</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>4.272355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.706932</td>\n",
       "      <td>-8.220344</td>\n",
       "      <td>-16.240454</td>\n",
       "      <td>-0.017374</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>4.272714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-13.686217</td>\n",
       "      <td>-8.176853</td>\n",
       "      <td>-16.211172</td>\n",
       "      <td>-0.017050</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>4.272765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10296</th>\n",
       "      <td>-13.345962</td>\n",
       "      <td>-7.450245</td>\n",
       "      <td>-16.820381</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>4.272202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10297</th>\n",
       "      <td>-13.212179</td>\n",
       "      <td>-7.291303</td>\n",
       "      <td>-16.704054</td>\n",
       "      <td>-0.013375</td>\n",
       "      <td>-0.004215</td>\n",
       "      <td>4.270268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10298</th>\n",
       "      <td>-13.128090</td>\n",
       "      <td>-7.172471</td>\n",
       "      <td>-16.438196</td>\n",
       "      <td>-0.006742</td>\n",
       "      <td>-0.007402</td>\n",
       "      <td>4.267761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10299</th>\n",
       "      <td>-13.115679</td>\n",
       "      <td>-7.122371</td>\n",
       "      <td>-16.095242</td>\n",
       "      <td>-0.001158</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>4.265383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10300</th>\n",
       "      <td>-13.178809</td>\n",
       "      <td>-7.156863</td>\n",
       "      <td>-15.768992</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>-0.007005</td>\n",
       "      <td>4.263744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10301 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x         y          z      roll     pitch       yaw\n",
       "0     -13.766946 -8.285960 -16.280176 -0.013512  0.000118  4.271540\n",
       "1     -13.746646 -8.279071 -16.282722 -0.015320  0.000157  4.271894\n",
       "2     -13.726923 -8.256329 -16.266628 -0.016726  0.000487  4.272355\n",
       "3     -13.706932 -8.220344 -16.240454 -0.017374  0.000828  4.272714\n",
       "4     -13.686217 -8.176853 -16.211172 -0.017050  0.000886  4.272765\n",
       "...          ...       ...        ...       ...       ...       ...\n",
       "10296 -13.345962 -7.450245 -16.820381 -0.019447  0.000266  4.272202\n",
       "10297 -13.212179 -7.291303 -16.704054 -0.013375 -0.004215  4.270268\n",
       "10298 -13.128090 -7.172471 -16.438196 -0.006742 -0.007402  4.267761\n",
       "10299 -13.115679 -7.122371 -16.095242 -0.001158 -0.008409  4.265383\n",
       "10300 -13.178809 -7.156863 -15.768992  0.001991 -0.007005  4.263744\n",
       "\n",
       "[10301 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_sgs_dataset['22_0641_pos.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-manor",
   "metadata": {},
   "source": [
    "# 2. Creating Node to generate Master Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "meaningful-aruba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user01/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from kedro_mlflow_tutorial.utils.estimator import estimate_natural_period\n",
    "\n",
    "def generate_master_data(\n",
    "        partitioned_input: Dict[str, Callable[[], Any]],\n",
    "        expected_tp: float,\n",
    "        target_column: 'str',\n",
    "        delta: float,\n",
    "        repetitions: int,\n",
    "        window_size: int,\n",
    "    ) -> pd.DataFrame:\n",
    "    '''\n",
    "    Generates the master table for training the regressor model, given\n",
    "    a partitioned dataset of time series. It estimates the natural period\n",
    "    of time series using the Welch's Method. It also calcuates statistics\n",
    "    of the time series.\n",
    "\n",
    "    Parameters:\n",
    "        partitioned_input (Dict[str, Callable[[], Any]]): kedro partitioned\n",
    "            dataset, which is dict of callables.\n",
    "        expected_tp (float): expected value for natural period\n",
    "        delta (float): the size of the segment used to filter\n",
    "            around the given center [center-delta,center+delta].\n",
    "        repetitions (int): number of repetitions to apply to\n",
    "            each window extracted from the time serie.\n",
    "        window_size (int): size of the window extracted from\n",
    "            the time serie.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        (pd.DataFrame): generated data\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for partition_key, partition_load_func in tqdm(\n",
    "            sorted(partitioned_input.items())\n",
    "        ):\n",
    "        # Initializes regressor_data dict and sets partition key\n",
    "        master_data = dict()\n",
    "        master_data['partition_key'] = partition_key\n",
    "\n",
    "        # Loading data with the partition function\n",
    "        if isinstance(partition_load_func, pd.DataFrame):\n",
    "            partition_data = partition_load_func\n",
    "        else:\n",
    "            partition_data = partition_load_func()\n",
    "\n",
    "        # Calculating statistics\n",
    "        statistics_data = calculate_position_statistics(partition_data)\n",
    "        master_data = {**master_data, **statistics_data}\n",
    "\n",
    "        # Calculating natural period\n",
    "        master_data[target_column], _, _, _, _ =  estimate_natural_period(\n",
    "            time_serie = partition_data[target_column.replace('tp_','')].values,\n",
    "            expected_tp = expected_tp,\n",
    "            delta = delta,\n",
    "            repetitions = repetitions,\n",
    "            window_size = window_size,\n",
    "        )\n",
    "\n",
    "        # Append generated data to final result\n",
    "        result.append(master_data)\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "\n",
    "def calculate_position_statistics(\n",
    "        data: pd.DataFrame,\n",
    "    ):\n",
    "\n",
    "    return {\n",
    "        'off_x': np.mean(data['x'].values),\n",
    "        'off_y': np.mean(data['y'].values),\n",
    "        'off_z': np.mean(data['z'].values),\n",
    "        'off_roll': np.mean(data['roll'].values),\n",
    "        'off_pitch': np.mean(data['pitch'].values),\n",
    "        'off_yaw': np.mean(data['yaw'].values),\n",
    "        'std_x': np.std(data['x'].values),\n",
    "        'std_y': np.std(data['y'].values),\n",
    "        'std_z': np.std(data['z'].values),\n",
    "        'std_roll': np.std(data['roll'].values),\n",
    "        'std_pitch': np.std(data['pitch'].values),\n",
    "        'std_yaw': np.std(data['yaw'].values),\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "supposed-south",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-23 23:48:35,025 - kedro.io.data_catalog - INFO - Loading data from `params:estimator.expected_tp` (MemoryDataSet)...\n",
      "2021-02-23 23:48:35,029 - kedro.io.data_catalog - INFO - Loading data from `params:estimator.target_column` (MemoryDataSet)...\n",
      "2021-02-23 23:48:35,031 - kedro.io.data_catalog - INFO - Loading data from `params:estimator.delta` (MemoryDataSet)...\n",
      "2021-02-23 23:48:35,036 - kedro.io.data_catalog - INFO - Loading data from `params:estimator.repetitions` (MemoryDataSet)...\n",
      "2021-02-23 23:48:35,038 - kedro.io.data_catalog - INFO - Loading data from `params:estimator.window_size` (MemoryDataSet)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user01/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:21<00:00,  4.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition_key</th>\n",
       "      <th>off_x</th>\n",
       "      <th>off_y</th>\n",
       "      <th>off_z</th>\n",
       "      <th>off_roll</th>\n",
       "      <th>off_pitch</th>\n",
       "      <th>off_yaw</th>\n",
       "      <th>std_x</th>\n",
       "      <th>std_y</th>\n",
       "      <th>std_z</th>\n",
       "      <th>std_roll</th>\n",
       "      <th>std_pitch</th>\n",
       "      <th>std_yaw</th>\n",
       "      <th>tp_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22_0001_pos.csv</td>\n",
       "      <td>-14.026536</td>\n",
       "      <td>-7.020101</td>\n",
       "      <td>-16.171808</td>\n",
       "      <td>-0.012766</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>4.267703</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.002520</td>\n",
       "      <td>6.504501e-07</td>\n",
       "      <td>7.134776e-07</td>\n",
       "      <td>1.536100e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>241.247035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22_0011_pos.csv</td>\n",
       "      <td>-13.371359</td>\n",
       "      <td>-5.791685</td>\n",
       "      <td>-16.171618</td>\n",
       "      <td>-0.011617</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>4.263764</td>\n",
       "      <td>0.330609</td>\n",
       "      <td>0.209626</td>\n",
       "      <td>1.255613e-01</td>\n",
       "      <td>3.697365e-03</td>\n",
       "      <td>2.940876e-03</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>244.871252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22_0021_pos.csv</td>\n",
       "      <td>-14.547890</td>\n",
       "      <td>-9.542539</td>\n",
       "      <td>-16.172542</td>\n",
       "      <td>-0.012871</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>4.273202</td>\n",
       "      <td>0.219257</td>\n",
       "      <td>0.763296</td>\n",
       "      <td>6.809988e-02</td>\n",
       "      <td>1.644666e-03</td>\n",
       "      <td>1.219647e-03</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>255.950522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22_0031_pos.csv</td>\n",
       "      <td>-15.055141</td>\n",
       "      <td>-9.202235</td>\n",
       "      <td>-16.171971</td>\n",
       "      <td>-0.013065</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>4.272791</td>\n",
       "      <td>0.339604</td>\n",
       "      <td>0.494314</td>\n",
       "      <td>1.648407e-01</td>\n",
       "      <td>6.344810e-03</td>\n",
       "      <td>3.801573e-03</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>247.662753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22_0041_pos.csv</td>\n",
       "      <td>-13.135397</td>\n",
       "      <td>-6.885676</td>\n",
       "      <td>-16.171561</td>\n",
       "      <td>-0.012622</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>4.267296</td>\n",
       "      <td>0.312190</td>\n",
       "      <td>0.201261</td>\n",
       "      <td>1.534357e-01</td>\n",
       "      <td>5.018621e-03</td>\n",
       "      <td>3.456325e-03</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>250.919454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     partition_key      off_x     off_y      off_z  off_roll  off_pitch  \\\n",
       "0  22_0001_pos.csv -14.026536 -7.020101 -16.171808 -0.012766   0.000500   \n",
       "1  22_0011_pos.csv -13.371359 -5.791685 -16.171618 -0.011617   0.000485   \n",
       "2  22_0021_pos.csv -14.547890 -9.542539 -16.172542 -0.012871   0.000504   \n",
       "3  22_0031_pos.csv -15.055141 -9.202235 -16.171971 -0.013065   0.000517   \n",
       "4  22_0041_pos.csv -13.135397 -6.885676 -16.171561 -0.012622   0.000480   \n",
       "\n",
       "    off_yaw     std_x     std_y         std_z      std_roll     std_pitch  \\\n",
       "0  4.267703  0.000478  0.002520  6.504501e-07  7.134776e-07  1.536100e-08   \n",
       "1  4.263764  0.330609  0.209626  1.255613e-01  3.697365e-03  2.940876e-03   \n",
       "2  4.273202  0.219257  0.763296  6.809988e-02  1.644666e-03  1.219647e-03   \n",
       "3  4.272791  0.339604  0.494314  1.648407e-01  6.344810e-03  3.801573e-03   \n",
       "4  4.267296  0.312190  0.201261  1.534357e-01  5.018621e-03  3.456325e-03   \n",
       "\n",
       "    std_yaw        tp_x  \n",
       "0  0.000006  241.247035  \n",
       "1  0.000752  244.871252  \n",
       "2  0.002004  255.950522  \n",
       "3  0.002368  247.662753  \n",
       "4  0.001367  250.919454  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_dataset = generate_master_data(\n",
    "    partitioned_input = transformed_sgs_dataset,\n",
    "    expected_tp = catalog.load(\"params:estimator.expected_tp\"),\n",
    "    target_column = catalog.load(\"params:estimator.target_column\"),\n",
    "    delta = catalog.load(\"params:estimator.delta\"),\n",
    "    repetitions = catalog.load(\"params:estimator.repetitions\"),\n",
    "    window_size = catalog.load(\"params:estimator.window_size\"),\n",
    ")\n",
    "\n",
    "master_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-globe",
   "metadata": {},
   "source": [
    "# 3. Creating a Node to generate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "collectible-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def generate_training_data(\n",
    "        master_dataset: pd.DataFrame,\n",
    "        target_column: str,\n",
    "        test_size: float,\n",
    "        valid_size: float,\n",
    "        shuffle: bool,\n",
    "    ):\n",
    "\n",
    "    # Generate Targets\n",
    "    X, Y = define_target_data(target_column, master_dataset)\n",
    "\n",
    "    # Scaling the data\n",
    "    X_scaled, X_scaler, Y_scaled, Y_scaler = scale_regressor_data(X,Y)\n",
    "\n",
    "    # Spliting the data\n",
    "    X_train, X_valid, X_test,Y_train, Y_valid, Y_test = split_data(\n",
    "        X,\n",
    "        Y,\n",
    "        test_size,\n",
    "        valid_size,\n",
    "        shuffle,\n",
    "    )\n",
    "\n",
    "    return X_train, X_valid, X_test, X_scaler, Y_train, Y_valid, Y_test, Y_scaler\n",
    "\n",
    "\n",
    "def define_target_data(\n",
    "        target_column: str,\n",
    "        master_dataset: pd.DataFrame\n",
    "    ) -> Tuple[pd.DataFrame]:\n",
    "\n",
    "    # Drop target column in X\n",
    "    X = master_dataset.drop(target_column, axis=1)\n",
    "\n",
    "    # Get target data\n",
    "    Y = master_dataset[target_column]\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def scale_regressor_data(\n",
    "        X: pd.DataFrame,\n",
    "        Y: pd.DataFrame,\n",
    "    ) -> Tuple[pd.DataFrame]:\n",
    "\n",
    "    # Set partition keys\n",
    "    partition_keys = X['partition_key']\n",
    "\n",
    "    # Scale X\n",
    "    X_scaled, X_scaler = scale_data(X.drop('partition_key', axis=1))\n",
    "\n",
    "    # Scale Y\n",
    "    Y_scaled, Y_scaler = scale_data(Y.values.reshape(-1,1))\n",
    "\n",
    "    X_scaled['partition_key'] = partition_keys\n",
    "\n",
    "    return X_scaled, X_scaler, Y_scaled, Y_scaler\n",
    "\n",
    "\n",
    "def scale_data(\n",
    "        data: Union[pd.DataFrame, np.ndarray],\n",
    "    ) -> Tuple:\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data)\n",
    "\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        scaled_data = pd.DataFrame(\n",
    "            scaler.transform(data),\n",
    "            columns = data.columns,\n",
    "            index = data.index\n",
    "        )\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        scaled_data = pd.DataFrame(\n",
    "            scaler.transform(data),\n",
    "            columns=['y']\n",
    "        )\n",
    "\n",
    "    return scaled_data, scaler\n",
    "\n",
    "\n",
    "def split_data(\n",
    "        X: pd.DataFrame,\n",
    "        Y: pd.DataFrame,\n",
    "        test_size: float,\n",
    "        valid_size: float,\n",
    "        shuffle: bool,\n",
    "    ) -> Tuple[pd.DataFrame]:\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        Y,\n",
    "        test_size=test_size,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "\n",
    "    if valid_size:\n",
    "\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            test_size=valid_size/(1 - test_size),\n",
    "            shuffle=shuffle\n",
    "        )\n",
    "\n",
    "        return x_train, x_valid, x_test, y_train, y_valid, y_test\n",
    "    else:\n",
    "        return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "apparent-radar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-23 23:50:03,487 - kedro.io.data_catalog - INFO - Loading data from `params:estimator.target_column` (MemoryDataSet)...\n",
      "2021-02-23 23:50:03,488 - kedro.io.data_catalog - INFO - Loading data from `params:regressor.test_size` (MemoryDataSet)...\n",
      "2021-02-23 23:50:03,491 - kedro.io.data_catalog - INFO - Loading data from `params:regressor.valid_size` (MemoryDataSet)...\n",
      "2021-02-23 23:50:03,492 - kedro.io.data_catalog - INFO - Loading data from `params:regressor.shuffle` (MemoryDataSet)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user01/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, X_test, X_scaler, Y_train, Y_valid, Y_test, Y_scaler = generate_training_data(\n",
    "    master_dataset = master_dataset,\n",
    "    target_column = catalog.load(\"params:estimator.target_column\"),\n",
    "    test_size = catalog.load(\"params:regressor.test_size\"),\n",
    "    valid_size = catalog.load(\"params:regressor.valid_size\"),\n",
    "    shuffle = catalog.load(\"params:regressor.shuffle\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-royalty",
   "metadata": {},
   "source": [
    "# 5. Next steps\n",
    "\n",
    "- 1. Update **nodes.py** file for data integration pipeline\n",
    "- 2. Update **pipeline.py** file for data integration pipeline\n",
    "- 3. Update **hooks.py** file\n",
    "- 4. Update **conf/base/catalog.yml** file\n",
    "- 5. **Commit code to repo**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KedroMLFlowTutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
